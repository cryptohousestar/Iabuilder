#!/usr/bin/env python3
"""
An√°lisis de diferencias entre modelos de Groq (Llama) vs OpenAI (GPT)
en la interpretaci√≥n de system prompts y function calling.
"""

def analyze_model_differences():
    """Analizar diferencias clave entre modelos de Groq y OpenAI."""

    print("üß† AN√ÅLISIS: Groq (Llama) vs OpenAI (GPT) - Diferencias en System Prompts")
    print("=" * 80)

    differences = {
        "Arquitectura Base": {
            "OpenAI (GPT)": "Transformer decoder-only, entrenado con instrucciones espec√≠ficas",
            "Groq (Llama)": "Transformer decoder-only, pero arquitectura m√°s abierta/conversacional",
            "Implicaci√≥n": "Llama puede ser m√°s flexible pero menos 'obediente' a reglas estrictas"
        },

        "Estilo de Fine-tuning": {
            "OpenAI (GPT)": "Fine-tuning extensivo para seguir instrucciones precisas",
            "Groq (Llama)": "Fine-tuning m√°s conservador, mantiene naturaleza conversacional",
            "Implicaci√≥n": "GPT responde mejor a prompts estructurados con reglas claras"
        },

        "Interpretaci√≥n de System Prompts": {
            "OpenAI (GPT)": "Trata system prompt como 'instrucciones estrictas a seguir'",
            "Groq (Llama)": "Trata system prompt como 'contexto conversacional'",
            "Implicaci√≥n": "Llama puede ignorar o reinterpretar reglas muy estrictas"
        },

        "Function Calling": {
            "OpenAI (GPT)": "Function calling nativo en el modelo",
            "Groq (Llama)": "Function calling implementado via API compatibility",
            "Implicaci√≥n": "Groq puede necesitar diferentes cues para activar tools"
        },

        "Longitud de Prompt": {
            "OpenAI (GPT)": "Maneja bien prompts largos con estructura clara",
            "Groq (Llama)": "Prefiere prompts m√°s concisos y directos",
            "Implicaci√≥n": "Prompts largos pueden confundir a Llama models"
        },

        "Estilo de Instrucci√≥n": {
            "OpenAI (GPT)": "Responde bien a: 'DEBES hacer X', 'SIEMPRE usa Y'",
            "Groq (Llama)": "Responde mejor a: 'Puedes usar X para...', 'Cuando necesites Y...'"
            "Implicaci√≥n": "El lenguaje imperativo puede ser contraproducente con Llama"
        }
    }

    for category, details in differences.items():
        print(f"\nüîç {category}:")
        print(f"   OpenAI: {details['OpenAI (GPT)']}")
        print(f"   Groq: {details['Groq (Llama)']}")
        print(f"   üí° Implicaci√≥n: {details['Implicaci√≥n']}")

    print("\n" + "=" * 80)
    print("üéØ HIP√ìTESIS: El System Prompt Actual Puede Ser Problem√°tico")
    print("=" * 80)

    current_prompt_issues = [
        "‚ùå MUY LARGO (125+ l√≠neas) - Llama prefiere conciso",
        "‚ùå Lenguaje IMPERATIVO ('MUST', 'STRICT', 'MANDATORY') - Llama m√°s flexible",
        "‚ùå Reglas DEMASIADO ESTRICTAS - Llama puede 'rebelarse' contra restricciones",
        "‚ùå Enfoque en 'prohibiciones' - Llama responde mejor a sugerencias positivas",
        "‚ùå Estructura compleja con secciones - Llama mejor con flujo natural",
        "‚ùå Asume comportamiento 'obediente' como GPT - Llama m√°s conversacional"
    ]

    for issue in current_prompt_issues:
        print(f"   {issue}")

    print("\nüí° SOLUCI√ìN PROPUESTA:")
    print("   Crear prompt optimizado para Llama models:")
    print("   - M√°s corto y conversacional")
    print("   - Lenguaje sugerente, no imperativo")
    print("   - Enfoque en capacidades, no restricciones")
    print("   - Ejemplos naturales, no reglas estrictas")

def compare_prompt_styles():
    """Comparar estilos de prompt para diferentes modelos."""

    print("\n" + "=" * 80)
    print("üìù COMPARACI√ìN: Estilos de Prompt Optimizados")
    print("=" * 80)

    # Prompt estilo OpenAI (actual)
    openai_style = """# ü§ñ AI Development Assistant - STRICT TOOL USAGE REQUIRED

You are a development assistant with access to tools. You MUST use tools for ALL development actions.

## üö® CRITICAL: ALWAYS USE TOOLS FOR:
### üìÅ FILE OPERATIONS (MANDATORY)
- **Creating files** ‚Üí `write_file`
- **Reading files** ‚Üí `read_file`

## üö´ ONLY USE PLAIN TEXT FOR:
- Greetings ("hola", "hello")
- Questions about your capabilities

## ‚ö†Ô∏è CRITICAL RULE:
**NEVER simulate actions with text. ALWAYS use tools for development tasks.**
**If you need to create/edit/read files: USE TOOLS IMMEDIATELY.**"""

    # Prompt estilo Groq/Llama optimizado
    llama_style = """# ü§ñ AI Assistant for Development

I'm a helpful AI with access to development tools. I can help you with coding tasks using these tools:

üìÅ Files: read_file, write_file, edit_file
üíª System: execute_bash, run_python
üîç Search: grep_search, glob_search

When you need to work with files or run commands, I'll automatically use the right tool.

For example:
- To read a file: I'll use read_file
- To run a command: I'll use execute_bash

What would you like to work on?"""

    print("\nüìã ESTILO ACTUAL (Optimizado para OpenAI/GPT):")
    print("-" * 50)
    for line in openai_style.split('\n')[:10]:
        print(f"   {line}")
    print("   ... (contin√∫a con reglas estrictas)")

    print("\nüéØ ESTILO PROPUESTO (Optimizado para Groq/Llama):")
    print("-" * 50)
    for line in llama_style.split('\n'):
        print(f"   {line}")

    print("\nüîÑ DIFERENCIAS CLAVE:")
    print("   OpenAI style: Reglas estrictas, imperativo, restricciones")
    print("   Llama style: Conversacional, sugerente, capacidades")
    print("   OpenAI style: 'DEBE usar tools SIEMPRE'")
    print("   Llama style: 'Puedo usar tools cuando ayude'")

if __name__ == "__main__":
    analyze_model_differences()
    compare_prompt_styles()